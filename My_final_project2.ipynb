{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "My_final_project2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBcZSaDCyI8I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "0907b7d2-70da-44ad-cb82-889467967021"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "import random\n",
        "nltk.download('punkt')\n",
        "from nltk import tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "nltk.download('stopwords')\n",
        "from itertools import chain"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vffxYamXyhSy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "64130648-7b6e-488a-e259-4abe20673948"
      },
      "source": [
        "data = pd.read_csv('BBB.csv')\n",
        "data.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-69d986ecd7bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'BBB.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'BBB.csv' does not exist: b'BBB.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YI6GNAvEA8hm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qaqt0_nFbr1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=data.fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUVUffT9y7sM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_stop_punct_from_paragrapghs(par):    # remove stop and punctuation word from paragraph.\n",
        "  tokenizer = RegexpTokenizer(r'\\w+')             # create an tokenizer object\n",
        "  tokens = tokenizer.tokenize(str(par).lower())  # first convert into lower case\n",
        "  stop_words = set(stopwords.words('english'))   # set of all stop word prasent in english dictonary\n",
        "  tokens = [w for w in tokens if not w in stop_words]\n",
        "  new_par= tokens\n",
        "  return new_par                               # paragraph without stop word "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQ816D730hk7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_stop_from_questions(que):   # remove stop and punctuation word from questions\n",
        "  tokenizer = RegexpTokenizer(r'\\w+')\n",
        "  tokens = tokenizer.tokenize(str(que).lower())   # first convert into lower case\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  tokens = [w for w in tokens if w in word_corpus if not w in stop_words]\n",
        "  new_que = tokens\n",
        "  return new_que\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eK91iUxW4sIZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Create_Paragraph_Topic_list(data):  #   data contain topics name  and paragraph\n",
        "  temp=[]\n",
        "  row_data=[]\n",
        "  for i in range(data.shape[0]):      \n",
        "    for j in tokenize.sent_tokenize(data['Paragraph'][i]):\n",
        "      temp.append((j,data['Paragraph'][i],data['Topic'][i]))   # list of tuple that contain sentence ,corresponding paragraph ,corr topic name\n",
        " \n",
        "  temp\n",
        "  for ele in temp:\n",
        "    if ele[0]!=0:        #due to space in the beg. we sometimes gets 0 in the sentence to remove we apply this\n",
        "      row_data.append(ele)   # we remove that statement which contains null in the beg.\n",
        "  return row_data\n",
        "row_data = Create_Paragraph_Topic_list(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riqtCvr1b2Z9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Creat_X(data):\n",
        "  C=Create_Paragraph_Topic_list(data)\n",
        "  sentence_list=[]\n",
        "  for i in range((len(C))):\n",
        "    sentence_list.append(remove_stop_from_questions(C[i][0]))\n",
        "  return sentence_list                                          # return sentence list without stop and punctuation word.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcdTlmtCAEgg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Creat_Y(data):\n",
        "  row_data = Create_Paragraph_Topic_list(data)\n",
        "  paragraph_list=[]\n",
        "  for i in range((len(row_data))):\n",
        "    paragraph_list.append(remove_stop_punct_from_paragrapghs(row_data[i][1]))\n",
        "  return paragraph_list\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvn0KaApeeYu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def creat_word_corpus(data):\n",
        "  par=Creat_Y(data)\n",
        "  #word_corpus=creat_word_corpus(par)\n",
        "  word_corpus= np.unique(np.array(list(chain.from_iterable(par))))\n",
        "  return word_corpus\n",
        "word_corpus=creat_word_corpus(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZK-9fk9S8_c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxcQ4haOcPdo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = Creat_X(data)\n",
        "Y = Creat_Y(data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puQ5kMzLf6Us",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gen_voc(w):\n",
        "  voc = {ch:i for i ,ch in enumerate(w)}\n",
        "  return voc\n",
        "voc =gen_voc(word_corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkMv9hbO6F8e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def multi_hot_encode(sequences, dimension):\n",
        "  results=np.zeros((len(sequences), dimension))\n",
        "  for i in range(len(sequences)):\n",
        "    for j in sequences[i]:\n",
        "      results[i][voc[j]]=1\n",
        "  return results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dk7S6R3tgcOH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = multi_hot_encode(X, word_corpus.shape[0])\n",
        "y = multi_hot_encode(Y, word_corpus.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSryr-9xpz-A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dict1={}\n",
        "for i in range(y.shape[0]):\n",
        "  dict1.update( {row_data[i][2] :y[i]} )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trpbXaYLg0tx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dtc =DecisionTreeClassifier()\n",
        "dtc.fit(x, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wrxRj96hXp5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def quen_test(Q,dict1):\n",
        "  q=np.array([Q])\n",
        "  q=q.reshape(1,-1)\n",
        "  q=remove_stop_from_questions(q)\n",
        "  q_test =  multi_hot_encode([q], word_corpus.shape[0])\n",
        "  ans= dtc.predict(q_test)\n",
        "  for key , value in dict1.items():\n",
        "    if (value==ans).all():\n",
        "      break\n",
        "  return key"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ah5htyTjRIN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Q='What type of TV companies would sell?'\n",
        "quen_test(Q,dict1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOY-lrv4escO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "question = pd.read_csv('questions.csv')\n",
        "question.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtRUTa9Ki5tt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def update_flag(sugst_list,s_value):\n",
        "  B = list(sugst_list.items())\n",
        "  C=sorted(B,key=lambda x: x[1], reverse=False)\n",
        "  simp=[]\n",
        "  for i in range(s_value):\n",
        "    simp.append(C[i][0])\n",
        "  return simp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvSrmbfJi7Cb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Start_Quiz(number_of_questions=10,s_value=2,mpq=1,negmark=0.25):\n",
        "  right_que = 0\n",
        "  wrong_que = 0\n",
        "  count_que = 1\n",
        "  nn = number_of_questions\n",
        "  l=[]\n",
        "  t_name=[]\n",
        "  s = (list(np.linspace(0,(question.shape[0]-1),question.shape[0],endpoint=True,dtype=int)))\n",
        "  \n",
        "  sugst_list = {ch:0 for i ,ch in enumerate(data['Topic'])}\n",
        "  while(number_of_questions>0):\n",
        "    simplicity =update_flag(sugst_list,s_value)\n",
        "    random.shuffle(s)\n",
        "    if quen_test(question['Questions'][s[0]],dict1) not in simplicity:\n",
        "      print('\\n')\n",
        "      print('\\n')\n",
        "      print(count_que,':',question['Questions'][s[0]],'\\n','a)',question['A'][s[0]],'\\n','b)',question['B'][s[0]],'\\n','c)',question['C'][s[0]],'\\n','d)',question['D'][s[0]],'\\n','*FOR SKIP PRESS ENTER')\n",
        "      print('\\n')\n",
        "      ans = input(\"Make your choice : \")\n",
        "      \n",
        "      \n",
        "      if ans.upper() == question['Answer'][s[0]]:\n",
        "          print(\"Correct!! \\U0001F44D\")\n",
        "          Y_predict = quen_test(question['Questions'][s[0]],dict1)\n",
        "          l.append((Y_predict,1))\n",
        "          t_name.append(Y_predict)\n",
        "          sugst_list[Y_predict] = sugst_list[Y_predict]+1\n",
        "          right_que+=1\n",
        "      elif ans.upper() ==\"\":\n",
        "        Y_predict = quen_test(question['Questions'][s[0]],dict1)\n",
        "        t_name.append(Y_predict)  \n",
        "        \n",
        "        \n",
        "      else:\n",
        "          print(\" Your answer is Incorrect!! \\U0001F44E\t \",'\\n',\"Correct option is:\",question['Answer'][s[0]].lower()) \n",
        "          Y_predict = quen_test(question['Questions'][s[0]],dict1)\n",
        "          l.append((Y_predict,0))\n",
        "          t_name.append(Y_predict)\n",
        "          sugst_list[Y_predict] = sugst_list[Y_predict]-1\n",
        "          wrong_que+=1\n",
        "        \n",
        "      \n",
        "        \n",
        "        \n",
        "      number_of_questions=number_of_questions-1\n",
        "      s.remove(s[0])\n",
        "      count_que+=1\n",
        "      \n",
        "    else:\n",
        "      random.shuffle(s) \n",
        "          \n",
        "  u_list=list(set(t_name))\n",
        "  l_wrong=[]\n",
        "  for i in range(len(l)):\n",
        "    if l[i][1]==0:\n",
        "      l_wrong.append(l[i][0])\n",
        "  l_right=[]\n",
        "  for i in range(len(l)):\n",
        "    if l[i][1]==1:\n",
        "      l_right.append(l[i][0])\n",
        "  std_list=[]\n",
        "  for i in range(len(l)):\n",
        "      std_list.append((l[i][0],l_right.count(l[i][0]),l_wrong.count(l[i][0])))\n",
        "  p =list(set(std_list))\n",
        "  res = []\n",
        "  only_prob=[]\n",
        "  for i in range(len(p)):\n",
        "    res.append((p[i][0],round(p[i][1]*100/(p[i][1]+p[i][2]),2)))\n",
        "    only_prob.append(round(p[i][1]*100/(p[i][1]+p[i][2]),2))\n",
        "  summary=pd.DataFrame(res,columns=['Topic', 'Percent(Right)'])\n",
        "  only_prob=np.sort(only_prob)\n",
        "  score_f = (right_que-wrong_que*negmark)*mpq\n",
        " \n",
        "  \n",
        "  return summary , right_que, wrong_que ,score_f,nn,only_prob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t03QvIzajHbx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "summary , right_que, wrong_que ,score_f,nn,only_prob= Start_Quiz(15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smw12mLi-U4T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Score(summary , right_que, wrong_que ,score_f,nn,only_prob):\n",
        "  print()\n",
        "  print('------------------------Score---------------------------')\n",
        "  print(\"Number of right question : \",right_que)\n",
        "  print(\"Number of wrong question : \",wrong_que)\n",
        "  print(\"     Your Total score is : \",round((score_f*100)/nn,2),'%')\n",
        "  #print('You need to highly revise again :->',list(fres[fres['Percent(Right)']==only_prob[0]]['Topic'])[0])\n",
        "  #print('And also focus on :->',list(fres[fres['Percent(Right)']==only_prob[1]]['Topic'])[0])\n",
        "  print('---------------FINAL SUMMARY--------------------')\n",
        "  \n",
        "  df = pd.DataFrame(list(np.array(summary['Percent(Right)'])), index=list(np.array(summary['Topic'])))\n",
        "\n",
        "  df.plot(kind='pie',autopct='%1.1f%%', subplots=True, figsize=(10, 10))\n",
        "\n",
        "  return summary\n",
        "Score(summary , right_que, wrong_que ,score_f,nn,only_prob)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_dNH_a1DhtF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}